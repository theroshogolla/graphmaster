# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MMExPZD_nbzCT7HP6MIGZcIHdfeUbgbb
"""

import numpy as np
import pandas as pd
from sklearn import svm
from support_network import support_network
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score 

FPATH = 'all_with_filtered_anotations_since1998.txt'
df = pd.read_csv(FPATH, engine='python', skiprows=4, sep='###')

df = df.reset_index()
df[['id', 'Date', 'Result', 'welo' ,'belo', 'len', 'date_c', 'resu_c', 'welo_c', 'belo_c',
    'edate_c', 'setup', 'fen', 'resu2_c', 'oyrange', 'bad_len']] = df['index'].str.split(' ', expand=True).iloc[:,:-1]
df['moves'] = df.iloc[:,1]
df['moves'] = df['moves'].str.replace('[WB]\d+?\.', '', regex=True)
df = df.iloc[:,2:].set_index('id')

def extract_features(graph, max_num_nodes=100):
    features = []

    # Extract node degrees
    degrees = list(dict(graph.degree()).values())
    features += degrees

    # Extract centrality measures
    closeness = list(nx.closeness_centrality(graph).values())
    features += closeness

    betweenness = list(nx.betweenness_centrality(graph).values())
    features += betweenness

    # Extract features based on the structure of the graph
    num_nodes = len(graph)
    num_edges = len(graph.edges())
    density = num_edges / (num_nodes * (num_nodes - 1) / 2)
    features.append(density)
    
    # Pad the feature vector with zeros to ensure that it has the same length
    # for each graph
    padding_length = max_num_nodes - len(features)
    if padding_length > 0:
        padding = np.zeros(padding_length)
        features += list(padding)

    return features

support_networks = []
for i in tqdm(range(len(df))):
    if(type(df.iloc[i]['moves']) != str):
        continue
    moves = io.StringIO(df.iloc[i]['moves'])
    game = chess.pgn.read_game(moves)
    game.headers.update(df.iloc[i].drop('moves', inplace=False))
    graphs = support_network(game)
    support_networks.append(graphs)

results = []
for result in df['Result']:
    if result == '1-0':
        results.append(1)
    elif result == '0-1':
        results.append(0)
    else:
        results.append(2)

X = []
for support_network in support_networks:
    for graph in support_network:
       X.append(extract_features(graph))

y = []
for i, result in enumerate(results):
    y.append([result]*len(support_networks[i]))

y_flat =[element for sublist in y for element in sublist]

X_train, X_test, y_train, y_test = train_test_split(X, y_flat, test_size=0.33)
X_train = np.asarray(X_train)
X_test = np.asarray(X_test)
y_train = np.asarray(y_train)
y_test = np.asarray(y_test)

print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

clf_svm = svm.SVC(kernel='linear', verbose=True)
clf_svm.fit(X_train, y_train)

y_pred = clf_svm.predict(X_test)

accuracy = accuracy_score(y_test,y_pred)*100
confusion_mat = confusion_matrix(y_test,y_pred)


clf_rf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42, verbose=True)
clf_rf.fit(X, y)

y_pred = clf_rf.predict(X_test)

accuracy = accuracy_score(y_test,y_pred)*100
confusion_mat = confusion_matrix(y_test,y_pred)